{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "import yt_dlp\n",
    "import json\n",
    "import time\n",
    "import math \n",
    "import httplib2\n",
    "import requests\n",
    "import pinecone \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.llms import OpenAIChat\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zak George GPT\n",
    "\n",
    "`Here, we will prepare the VectorDB index for Zak George's YouTube channel:`\n",
    "\n",
    "* Use Whisper to transcribe episodes \n",
    "* Chunk data\n",
    "* Embed it to Pinecone\n",
    "* Test VectorDBQA chain on it \n",
    " \n",
    "`1. Get video urls -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from youtubesearchpython import *\n",
    "import yt_dlp\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_channel_title(s: str) -> str:\n",
    "    s = s.lower().replace(\" \", \"-\")\n",
    "    return \"\".join(c for c in s if c.isalnum() or c == \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_title = 'Dog Training by Kikopup'\n",
    "cleaned_channel_title = cleaned_channel_title(channel_title)\n",
    "channelsSearch = ChannelsSearch(channel_title, limit = 1, region = 'US')\n",
    "channel_id = channelsSearch.result()['result'][0]['id']\n",
    "print(f\"Retrived {channelsSearch.result()['result'][0]['title']} channel ID: {channelsSearch.result()['result'][0]['id']}\")\n",
    "\n",
    "# https://pypi.org/project/youtube-search-python/\n",
    "playlist = Playlist(playlist_from_channel_id(channel_id))\n",
    "\n",
    "while playlist.hasMoreVideos:\n",
    "    print('Getting more videos...')\n",
    "    playlist.getNextVideos()\n",
    "    print(f'Videos Retrieved: {len(playlist.videos)}')\n",
    "    \n",
    "# Episode data\n",
    "stor_metadata=pd.DataFrame()\n",
    "for v in playlist.videos:\n",
    "    try:\n",
    "        stor_metadata.loc[v['title'],'link']=v['link']\n",
    "        stor_metadata.loc[v['title'],'title']=v['title']\n",
    "        stor_metadata.loc[v['title'],'img']=v['thumbnails'][3]['url']\n",
    "    except:\n",
    "        print(\"Failed on %s\", v['title'])\n",
    "        \n",
    "# Adds a numerical index to the dataframe which we'll use later\n",
    "stor_metadata = stor_metadata.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. Get audio -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_episode(ep_number, img_url, ep_link, channel_title):\n",
    "    \"\"\"Downloads an episode of a YouTube channel.\n",
    "\n",
    "    Args:\n",
    "        ep_number (int): The episode number.\n",
    "        img_url (str): The URL of the episode image.\n",
    "        ep_link (str): The URL of the episode video.\n",
    "        channel_title (str): The title of the YouTube channel as shown on the channel.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    _cleaned_title = clean_channel_title(channel_title)\n",
    "    \n",
    "    # Check if the directory exists\n",
    "    directory_name = f\"../public/{_cleaned_title}\"\n",
    "    if not os.path.exists(directory_name):\n",
    "        # Create the directory\n",
    "        os.makedirs(directory_name)\n",
    "\n",
    "    # Write the image to the directory\n",
    "    with open(f\"{directory_name}/0{ep_number}.jpg\", 'wb') as f:\n",
    "        response = requests.get(img_url)\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Write the audio to the directory\n",
    "    ydl_opts = {\n",
    "        'format': 'm4a/bestaudio/best',\n",
    "        'outtmpl': f'audio/{_cleaned_title}/{ep_number}.m4a',\n",
    "        'noplaylist': True,\n",
    "        'postprocessors': [{  \n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'm4a',\n",
    "        }]}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        error_code = ydl.download(ep_link)\n",
    "\n",
    "    # Log the episode information\n",
    "    logging.info(f\"Downloaded episode {ep_number}\")\n",
    "\n",
    "\n",
    "# Iterate through episodes \n",
    "for ix in stor_metadata.index:\n",
    "    ep_number=ix\n",
    "    print(\"EPISODE: %s\"%ep_number)\n",
    "    img_url=stor_metadata.loc[ix,'img']\n",
    "    ep_link=stor_metadata.loc[ix,'link']\n",
    "    # Write img \n",
    "    download_episode(ep_number, img_url, ep_link)\n",
    "\n",
    "# Write the metadata to a CSV file\n",
    "stor_metadata.to_csv(f\"audio_transcription/{cleaned_channel_title}/episodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. Run Whisper -`\n",
    " \n",
    "* On GPU, ideally: 10-20 min / video on 2080Ti with `medium` model\n",
    "* Run `python run_whisper.py`\n",
    "\n",
    "If running this step on a remote machine:\n",
    "* scp the transcription: `audio_transcription/episodes.csv`\n",
    "* scp the audio files: `audio/*`\n",
    "* Run `python run_whisper.py`\n",
    "* Then, scp the `audio_transcription/` back to local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_whisper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4. Get transcripts -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Chunk size: key parameter *** \n",
    "chunks = 1500\n",
    "splits_new = [ ]\n",
    "metadatas_new = [ ]\n",
    "\n",
    "# Read the csv file\n",
    "new_ep=pd.read_csv(\"audio_transcription/episodes.csv\",index_col=None)\n",
    "\n",
    "for ix in new_ep.index:\n",
    "\n",
    "    # Get data\n",
    "    title=new_ep.loc[ix,'title']\n",
    "    ep_number=int(new_ep.loc[ix,'number'])\n",
    "    \n",
    "    # Ep\n",
    "    episode_id=\"0\"+str(ep_number) \n",
    "    file_path='audio_transcription/%s.txt'%str(episode_id)\n",
    "    transcript=pd.read_csv(file_path,sep='\\t',header=None)\n",
    "    transcript.columns=['links','time','chunks']\n",
    "    \n",
    "    # Clean text chunks \n",
    "    transcript['clean_chunks']=transcript['chunks'].astype(str).apply(lambda x: x.strip())\n",
    "    links = list(transcript['links'])\n",
    "    texts = transcript['clean_chunks'].str.cat(sep=' ')\n",
    "\n",
    "    # Splits \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunks, \n",
    "                                                   chunk_overlap=50) \n",
    "    splits = text_splitter.split_text(texts)\n",
    "    print(len(splits)) \n",
    "\n",
    "    # Metadata \n",
    "    N = len(splits) \n",
    "    bins = np.linspace(0, len(links)-1, N, dtype=int)\n",
    "    sampled_links = [links[i] for i in bins]\n",
    "    \n",
    "    # Here we can add \"link\", \"title\", etc that can be fetched in the app \n",
    "    metadatas=[{\"source\":title + \" \" +link,\"id\":episode_id,\"link\":link,\"title\":title} for link in sampled_links]\n",
    "    print(len(metadatas)) \n",
    "\n",
    "    # Append to output \n",
    "    splits_new.append(splits)\n",
    "    metadatas_new.append(metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5. Assemble final list -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the list of lists \n",
    "splits_all = []\n",
    "for sublist in splits_new:\n",
    "    splits_all.extend(sublist)\n",
    "\n",
    "metadatas_all = []\n",
    "for sublist in metadatas_new:\n",
    "    metadatas_all.extend(sublist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6. Embed full dataset in Pinecone VectorDB -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-west4-gcp\")\n",
    "\n",
    "# Update - \n",
    "index_name = \"zac-george-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data in chunk to avoid data ingest errors\n",
    "chunk_size = 100\n",
    "last_chunk = 0\n",
    "num_chunks = math.ceil(len(splits_all) / chunk_size)\n",
    "for i in range(last_chunk,num_chunks):\n",
    "    \n",
    "    print(i)\n",
    "    start_time = time.time()\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min(start_idx + chunk_size, len(splits_all))\n",
    "    \n",
    "    # Extract the current chunk\n",
    "    current_splits = splits_all[start_idx:end_idx]\n",
    "    current_metadatas = metadatas_all[start_idx:end_idx]\n",
    "    \n",
    "    # Add the current chunk to the vector database\n",
    "    p.add_texts(texts = current_splits, metadatas=current_metadatas)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7. Read in VectorDB for testing` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-west4-gcp\")\n",
    "index_name = \"zac-george-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_retrievalQA_sources_chain(llm,query,docstore):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chain = RetrievalQAWithSourcesChain.from_chain_type(llm,chain_type=\"stuff\",retriever=docstore.as_retriever(k=3))\n",
    "    a = chain({\"question\": query},return_only_outputs=True)\n",
    "    print(a[\"answer\"])\n",
    "    print(a[\"sources\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")\n",
    "\n",
    "def run_vectorDBQA_sources_chain(llm,query,docstore,k):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chain = VectorDBQAWithSourcesChain.from_chain_type(llm,chain_type=\"stuff\",vectorstore=docstore,k=k)\n",
    "    a = chain({\"question\": query},return_only_outputs=True)\n",
    "    print(a[\"answer\"])\n",
    "    print(a[\"sources\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAIChat(temperature=0)\n",
    "q = \"What are the first things I need to train my new dog?\"\n",
    "run_vectorDBQA_sources_chain(llm,q,p,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAIChat(model_name=\"gpt-4\",temperature=0)\n",
    "q = \"What is the first thing to do when I get a new puppy?\"\n",
    "run_vectorDBQA_sources_chain(llm,q,p,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`8. Evaluation` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('eval/final_eval.json', 'r') as f:\n",
    "    eval_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "\n",
    "llm = OpenAIChat(temperature=0)\n",
    "chain_gpt3_k_1 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=1,input_key = \"question\")\n",
    "chain_gpt3_k_4 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=4,input_key = \"question\")\n",
    "\n",
    "llm = OpenAIChat(model_name=\"gpt-4\",temperature=0)\n",
    "chain_gpt4_k_1 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=1,input_key = \"question\")\n",
    "chain_gpt4_k_4 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=4,input_key = \"question\")\n",
    "chain_gpt4_k_8 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=8,input_key = \"question\")\n",
    " \n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "eval_chain = QAEvalChain.from_llm(llm=ChatOpenAI(temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(chain):\n",
    "\n",
    "    predictions = []\n",
    "    predicted_dataset = []\n",
    "    latency = []\n",
    "\n",
    "    for data in eval_set:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        new_data = {\"question\": data[\"question\"],\"answer\": data[\"answer\"]}\n",
    "        predictions.append(chain(new_data))\n",
    "        predicted_dataset.append(new_data)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        latency.append(elapsed_time)\n",
    "\n",
    "    return predictions,predicted_dataset,latency\n",
    "\n",
    "predictions_list = []\n",
    "scores_list = []\n",
    "latency_list = []\n",
    "\n",
    "# Eval on chains \n",
    "for i,chain in enumerate([chain_gpt3_k_1,chain_gpt4_k_1,chain_gpt3_k_4,chain_gpt4_k_4,chain_gpt4_k_8]):    \n",
    "    print(f\"Evaluating chain {i+1}\")\n",
    "    predictions,predicted_dataset,latency=run_eval(chain)\n",
    "    predictions_list.append(predictions)\n",
    "    graded_outputs = eval_chain.evaluate(predicted_dataset, predictions, question_key=\"question\", prediction_key=\"result\")\n",
    "    scores_list.append(graded_outputs)\n",
    "    latency_list.append(latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "stor=pd.DataFrame()\n",
    "\n",
    "for i,chunk_size in enumerate([\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]):\n",
    "    d=scores_list[i]\n",
    "    incorrect_counts = []\n",
    "    for dictionary in d:\n",
    "        if dictionary['text'] == 'INCORRECT':\n",
    "            incorrect_counts.append(1)\n",
    "        else:\n",
    "            incorrect_counts.append(0)\n",
    "    stor.loc[chunk_size,'num_incorrect']=sum(incorrect_counts)\n",
    "\n",
    "stor['pct_incorrect'] = stor['num_incorrect']  / len(eval_set)\n",
    "stor['pct_correct'] = 1 - stor['pct_incorrect']\n",
    "stor['pct_correct'].plot(kind='bar')\n",
    "plt.title('Percentage of Correct Answers')\n",
    "plt.xlabel('Chain')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency=pd.DataFrame(latency_list).T\n",
    "latency.columns = [\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]\n",
    "latency.to_csv(\"results/latency.csv\")\n",
    "latency.boxplot()\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Latency per query (seconds)\")\n",
    "plt.title(\"Latency for QA comparing ChatGPT vs GPT4 \\n $\\mu$ per model = 4.7s,13.3s,19.1s, $N=52$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_summary(i):\n",
    "    d=pd.DataFrame(predictions_list[i])\n",
    "    d['score']=list(score[\"text\"] for score in scores_list[i])\n",
    "    return d\n",
    "\n",
    "GPT35_k_4_result=eval_summary(0)\n",
    "GPT4_k_4_result=eval_summary(1)\n",
    "GPT4_k_8_result=eval_summary(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT35_k_4_result.to_csv(\"results/GPT35_k_4_result.csv\")\n",
    "GPT4_k_4_result.to_csv(\"results/GPT4_k_4_result.csv\")\n",
    "GPT4_k_8_result.to_csv(\"results/GPT4_k_8_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong3_5=GPT35_k_4_result[GPT35_k_4_result.score != \"CORRECT\"]\n",
    "wrong3_5.to_csv(\"results/wrong3_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4=GPT4_k_4_result[GPT4_k_4_result.score != \"CORRECT\"]\n",
    "wrong4.to_csv(\"results/wrong4_k4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4=GPT4_k_4_result[GPT4_k_4_result.score != \"CORRECT\"]\n",
    "wrong4.to_csv(\"results/wrong4_k8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT35_k_4_result=pd.read_csv(\"results/GPT35_k_4_result.csv\")\n",
    "GPT4_k_4_result=pd.read_csv(\"results/GPT4_k_4_result.csv\")\n",
    "GPT4_k_8_result=pd.read_csv(\"results/GPT4_k_8_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include corrections to eval (see below):\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1zc3lmm23lRkbU0k0j3ueo69_s5RBb-1qbXGwnx0PW00/edit#gid=1347589790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame([48/51.,50/51.,51/51.]).T\n",
    "d.columns=[\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]\n",
    "d_=d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency = pd.read_csv(\"results/latency.csv\",index_col=None)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "axs[0].set_title(\"Percentage of Correct Answers \\n % per model: 94%, 98%, 100%, $N=52$\")\n",
    "axs[1].set_title(\"Latency for QA comparing ChatGPT vs GPT4 \\n $\\mu$ per model: 4.7s,13.3s,19.1s, $N=52$\")\n",
    "axs[0].set_xlabel('Chain')\n",
    "axs[0].set_ylabel('Fraction correct')\n",
    "axs[1].set_xlabel(\"Model\")\n",
    "axs[1].set_ylabel(\"Latency per query (seconds)\")\n",
    "d_.plot(kind='bar', ax=axs[0], legend=False)\n",
    "latency[[\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]].boxplot(ax=axs[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
