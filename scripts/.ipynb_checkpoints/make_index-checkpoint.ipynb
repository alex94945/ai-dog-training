{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayoung/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,re\n",
    "import yt_dlp\n",
    "import json\n",
    "import time\n",
    "import math \n",
    "import httplib2\n",
    "import requests\n",
    "import pinecone \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import matplotlib.pyplot as plt\n",
    "from youtubesearchpython import *\n",
    "from langchain.llms import OpenAIChat\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zak George GPT\n",
    "\n",
    "`Here, we will prepare the VectorDB index for Zac George's YouTube channel:`\n",
    "\n",
    "* Use Whisper to transcribe episodes \n",
    "* Chunk data\n",
    "* Embed it to Pinecone\n",
    "* Test VectorDBQA chain on it \n",
    " \n",
    "`1. Get video urls -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtubesearchpython import ChannelsSearch\n",
    "channelsSearch = ChannelsSearch('Zak Georgeâ€™s Dog Training Revolution', limit = 3, region = 'US')\n",
    "channel_id = channelsSearch.result()['result'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/youtube-search-python/\n",
    "playlist = Playlist(playlist_from_channel_id(channel_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while playlist.hasMoreVideos:\n",
    "    print('Getting more videos...')\n",
    "    playlist.getNextVideos()\n",
    "    print(f'Videos Retrieved: {len(playlist.videos)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode data\n",
    "stor_metadata=pd.DataFrame()\n",
    "for v in playlist.videos:\n",
    "    try:\n",
    "        stor_metadata.loc[v['title'],'link']=v['link']\n",
    "        stor_metadata.loc[v['title'],'title']=v['title']\n",
    "        stor_metadata.loc[v['title'],'img']=v['thumbnails'][3]['url']\n",
    "    except:\n",
    "        print(\"Failed on %s\", v['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stor_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. Get audio -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through episodes \n",
    "for ix in stor_metadata.reset_index().index:\n",
    "    if ix = 512:\n",
    "        continue\n",
    "    else:\n",
    "        ep_number=ix\n",
    "        print(\"EPISODE: %s\"%ep_number)\n",
    "        img_url=stor_metadata.loc[ix,'img']\n",
    "        ep_link=stor_metadata.loc[ix,'link']\n",
    "        # Write img \n",
    "        with open(\"../public/0%s.jpg\"%str(ep_number), 'wb') as f:\n",
    "            response = requests.get(img_url)\n",
    "            f.write(response.content)\n",
    "        # Write audio\n",
    "        ydl_opts = {\n",
    "        'format': 'm4a/bestaudio/best',\n",
    "        'outtmpl': 'audio/%s.m4a'%str(ep_number),\n",
    "        'noplaylist': True,\n",
    "        'postprocessors': [{  \n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'm4a',\n",
    "        }]}\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            error_code = ydl.download(ep_link)\n",
    "        \n",
    "stor_metadata.reset_index().to_csv(\"audio_transcription/episodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. Run Whisper -`\n",
    " \n",
    "* On GPU, ideally: 10-20 min / video on 2080Ti with `medium` model\n",
    "* Run `python run_whisper.py`\n",
    "\n",
    "If running this step on a remote machine:\n",
    "* scp the transcription: `audio_transcription/episodes.csv`\n",
    "* scp the audio files: `audio/*`\n",
    "* Run `python run_whisper.py`\n",
    "* Then, scp the `audio_transcription/` back to local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_whisper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4. Get transcripts -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "11\n",
      "11\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "11\n",
      "11\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "42\n",
      "42\n",
      "9\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "11\n",
      "11\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "9\n",
      "11\n",
      "11\n",
      "10\n",
      "10\n",
      "122\n",
      "122\n",
      "8\n",
      "8\n",
      "24\n",
      "24\n",
      "17\n",
      "17\n",
      "15\n",
      "15\n",
      "12\n",
      "12\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "12\n",
      "12\n",
      "9\n",
      "9\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "11\n",
      "11\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "14\n",
      "14\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "16\n",
      "16\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "19\n",
      "19\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "17\n",
      "17\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "16\n",
      "16\n",
      "4\n",
      "4\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "17\n",
      "17\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "1\n",
      "1\n",
      "19\n",
      "19\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "11\n",
      "11\n",
      "8\n",
      "8\n",
      "17\n",
      "17\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "10\n",
      "10\n",
      "16\n",
      "16\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "16\n",
      "16\n",
      "19\n",
      "19\n",
      "22\n",
      "22\n",
      "1\n",
      "1\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "3\n",
      "13\n",
      "13\n",
      "31\n",
      "31\n",
      "14\n",
      "14\n",
      "19\n",
      "19\n",
      "21\n",
      "21\n",
      "17\n",
      "17\n",
      "12\n",
      "12\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "22\n",
      "22\n",
      "2\n",
      "2\n",
      "13\n",
      "13\n",
      "10\n",
      "10\n",
      "26\n",
      "26\n",
      "12\n",
      "12\n",
      "18\n",
      "18\n",
      "12\n",
      "12\n",
      "17\n",
      "17\n",
      "12\n",
      "12\n",
      "15\n",
      "15\n",
      "23\n",
      "23\n",
      "16\n",
      "16\n",
      "19\n",
      "19\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "21\n",
      "21\n",
      "23\n",
      "23\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "20\n",
      "20\n",
      "30\n",
      "30\n",
      "3\n",
      "3\n",
      "8\n",
      "8\n",
      "21\n",
      "21\n",
      "17\n",
      "17\n",
      "16\n",
      "16\n",
      "25\n",
      "25\n",
      "19\n",
      "19\n",
      "18\n",
      "18\n",
      "17\n",
      "17\n",
      "19\n",
      "19\n",
      "24\n",
      "24\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "31\n",
      "31\n",
      "2\n",
      "2\n",
      "12\n",
      "12\n",
      "15\n",
      "15\n",
      "20\n",
      "20\n",
      "14\n",
      "14\n",
      "8\n",
      "8\n",
      "15\n",
      "15\n",
      "7\n",
      "7\n",
      "18\n",
      "18\n",
      "9\n",
      "9\n",
      "18\n",
      "18\n",
      "11\n",
      "11\n",
      "9\n",
      "9\n",
      "16\n",
      "16\n",
      "10\n",
      "10\n",
      "16\n",
      "16\n",
      "21\n",
      "21\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "18\n",
      "18\n",
      "17\n",
      "17\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "16\n",
      "16\n",
      "20\n",
      "20\n",
      "34\n",
      "34\n",
      "2\n",
      "2\n",
      "7\n",
      "7\n",
      "10\n",
      "10\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "11\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "13\n",
      "13\n",
      "9\n",
      "9\n",
      "11\n",
      "11\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "12\n",
      "12\n",
      "9\n",
      "9\n",
      "12\n",
      "12\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "13\n",
      "13\n",
      "10\n",
      "10\n",
      "5\n",
      "5\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "10\n",
      "10\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "17\n",
      "17\n",
      "15\n",
      "15\n",
      "13\n",
      "13\n",
      "23\n",
      "23\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "13\n",
      "13\n",
      "16\n",
      "16\n",
      "22\n",
      "22\n",
      "9\n",
      "9\n",
      "12\n",
      "12\n",
      "19\n",
      "19\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "14\n",
      "22\n",
      "22\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "23\n",
      "23\n",
      "8\n",
      "8\n",
      "13\n",
      "13\n",
      "11\n",
      "11\n",
      "9\n",
      "9\n",
      "13\n",
      "13\n",
      "16\n",
      "16\n",
      "11\n",
      "11\n",
      "19\n",
      "19\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "2\n",
      "2\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "1\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "10\n",
      "10\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "9\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "1\n",
      "1\n",
      "5\n",
      "5\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "8\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'audio_transcription/0512.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m episode_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(ep_number) \n\u001b[1;32m     17\u001b[0m file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_transcription/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mstr\u001b[39m(episode_id)\n\u001b[0;32m---> 18\u001b[0m transcript\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m transcript\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Clean text chunks \u001b[39;00m\n",
      "File \u001b[0;32m~/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audio_transcription/0512.txt'"
     ]
    }
   ],
   "source": [
    "# *** Chunk size: key parameter *** \n",
    "chunks = 1500\n",
    "splits_new = [ ]\n",
    "metadatas_new = [ ]\n",
    "\n",
    "# Read the csv file\n",
    "new_ep=pd.read_csv(\"audio_transcription/episodes.csv\",index_col=None)\n",
    "\n",
    "for ix in new_ep.index:\n",
    "\n",
    "    # Get data\n",
    "    title=new_ep.loc[ix,'title']\n",
    "    ep_number=int(new_ep.loc[ix,'number'])\n",
    "    \n",
    "    # Ep\n",
    "    episode_id=\"0\"+str(ep_number) \n",
    "    file_path='audio_transcription/%s.txt'%str(episode_id)\n",
    "    transcript=pd.read_csv(file_path,sep='\\t',header=None)\n",
    "    transcript.columns=['links','time','chunks']\n",
    "    \n",
    "    # Clean text chunks \n",
    "    transcript['clean_chunks']=transcript['chunks'].astype(str).apply(lambda x: x.strip())\n",
    "    links = list(transcript['links'])\n",
    "    texts = transcript['clean_chunks'].str.cat(sep=' ')\n",
    "\n",
    "    # Splits \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunks, \n",
    "                                                   chunk_overlap=50) \n",
    "    splits = text_splitter.split_text(texts)\n",
    "    print(len(splits)) \n",
    "\n",
    "    # Metadata \n",
    "    N = len(splits) \n",
    "    bins = np.linspace(0, len(links)-1, N, dtype=int)\n",
    "    sampled_links = [links[i] for i in bins]\n",
    "    \n",
    "    # Here we can add \"link\", \"title\", etc that can be fetched in the app \n",
    "    metadatas=[{\"source\":title + \" \" +link,\"id\":episode_id,\"link\":link,\"title\":title} for link in sampled_links]\n",
    "    print(len(metadatas)) \n",
    "\n",
    "    # Append to output \n",
    "    splits_new.append(splits)\n",
    "    metadatas_new.append(metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5. Assemble final list -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the list of lists \n",
    "splits_all = []\n",
    "for sublist in splits_new:\n",
    "    splits_all.extend(sublist)\n",
    "\n",
    "metadatas_all = []\n",
    "for sublist in metadatas_new:\n",
    "    metadatas_all.extend(sublist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6. Embed full dataset in Pinecone VectorDB -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-west4-gcp\")\n",
    "\n",
    "# Update - \n",
    "index_name = \"zac-george-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812a08454d684d11839f93040d51b500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 41.869946002960205 seconds\n",
      "--------\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51568cedaaf4f0db30bd7a0b7259614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 31.478826999664307 seconds\n",
      "--------\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6d754eac2f488ba1cbcde03a8534b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.47222399711609 seconds\n",
      "--------\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2477362ec22451bb1341a8bee6c5906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.16791605949402 seconds\n",
      "--------\n",
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597e36f1bb424919bbd2b57341a5a7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 48.87401294708252 seconds\n",
      "--------\n",
      "5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585e792d6e484f6f90f486c66f754af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 31.676391124725342 seconds\n",
      "--------\n",
      "6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dd95c61f08401289a7f0470ba822eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.973806858062744 seconds\n",
      "--------\n",
      "7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d6fc74d2ca46ecab254e5de2e8f6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.814249992370605 seconds\n",
      "--------\n",
      "8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712a61513d6d48b9928041e8ab679833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.299412965774536 seconds\n",
      "--------\n",
      "9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701429b6ee0f4a78ab06c0f8cd7a5c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.718105792999268 seconds\n",
      "--------\n",
      "10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4032d4c94aa45a8ad0acd920564b686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 30.078527212142944 seconds\n",
      "--------\n",
      "11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0284ce9af08b4ba89ea0e50a9f6ba326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 31.33049488067627 seconds\n",
      "--------\n",
      "12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9859883cb0604a488f7d2e8c7ebf415e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 29.78966188430786 seconds\n",
      "--------\n",
      "13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed2a0e18c0c4d7e8c073d153d2374a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 29.401406049728394 seconds\n",
      "--------\n",
      "14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ccf07d68d84bc2a3dcdc7f4ea1cd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 35.59206509590149 seconds\n",
      "--------\n",
      "15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69c5a0d14cc4ff39c558673d1a151f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.710402011871338 seconds\n",
      "--------\n",
      "16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158ff70af7a3435b98500d9402683a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 35.04147911071777 seconds\n",
      "--------\n",
      "17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eac4fe313444533ab05a6141f184f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 28.496302843093872 seconds\n",
      "--------\n",
      "18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e695e0638318449ba7b53213b777e76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 29.352944135665894 seconds\n",
      "--------\n",
      "19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451a4766c95744d9a413a7ed05b2913f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.67032217979431 seconds\n",
      "--------\n",
      "20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ceb34800094ccca166efee3801f718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 30.859798908233643 seconds\n",
      "--------\n",
      "21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c4f91f90dc4d02ab1a4b6817dfff61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 35.190645933151245 seconds\n",
      "--------\n",
      "22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11fedca89c94d30b7eacd05d1570896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 28.62360978126526 seconds\n",
      "--------\n",
      "23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f509d0300549eab15e5dfc3d440ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 30.895238876342773 seconds\n",
      "--------\n",
      "24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a417e49657a447e8e1a7024b98014de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 31.892035961151123 seconds\n",
      "--------\n",
      "25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c33df4601d49068b2768973df292e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 26.716665029525757 seconds\n",
      "--------\n",
      "26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01397a28b5c405584d88ca5357ae1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 30.207765102386475 seconds\n",
      "--------\n",
      "27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a6e7958b3e413f8e06a605d18d7011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 28.220741033554077 seconds\n",
      "--------\n",
      "28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163526decb6f4611a5b67c2082ef5516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 28.691686868667603 seconds\n",
      "--------\n",
      "29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2274752903d84d8da35c9d265817d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.75520896911621 seconds\n",
      "--------\n",
      "30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606e204ffeef4d718df555908a6b694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.516934871673584 seconds\n",
      "--------\n",
      "31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10b24e5506e4c4895f93b6db975ce47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 29.704950094223022 seconds\n",
      "--------\n",
      "32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcbbe4fb76f44babffb1acdc5547907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 23.61732792854309 seconds\n",
      "--------\n",
      "33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519ac8c25f0c43099a383d002e7379ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.28375816345215 seconds\n",
      "--------\n",
      "34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c6d28816ad48839b74270bfdc9dfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 26.853689193725586 seconds\n",
      "--------\n",
      "35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f4938aea7f4190b637aa6604ffd82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.324007749557495 seconds\n",
      "--------\n",
      "36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb3184bdbd84417860528c58376055a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 57.81608200073242 seconds\n",
      "--------\n",
      "37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a657037a0024342b8b67d80deb9d589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 31.305824041366577 seconds\n",
      "--------\n",
      "38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4eeafebe3f4a86b9eb17797e6f30a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.47455096244812 seconds\n",
      "--------\n",
      "39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c14944062a4f749b733847d36dc99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 28.525768041610718 seconds\n",
      "--------\n",
      "40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85c09a3239645b2925d89cf70fdb9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 29.841968059539795 seconds\n",
      "--------\n",
      "41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aae95b357e40a89fa335ccb7b40c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 31.786036252975464 seconds\n",
      "--------\n",
      "42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b76d79f6f0e4654a02ac041388f685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.388741970062256 seconds\n",
      "--------\n",
      "43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fee4f8f9fae4b5f85b4075e7a05116e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 8.91594910621643 seconds\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# Add data in chunk to avoid data ingest errors\n",
    "chunk_size = 100\n",
    "last_chunk = 0\n",
    "num_chunks = math.ceil(len(splits_all) / chunk_size)\n",
    "for i in range(last_chunk,num_chunks):\n",
    "    \n",
    "    print(i)\n",
    "    start_time = time.time()\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min(start_idx + chunk_size, len(splits_all))\n",
    "    \n",
    "    # Extract the current chunk\n",
    "    current_splits = splits_all[start_idx:end_idx]\n",
    "    current_metadatas = metadatas_all[start_idx:end_idx]\n",
    "    \n",
    "    # Add the current chunk to the vector database\n",
    "    p.add_texts(texts = current_splits, metadatas=current_metadatas)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7. Read in VectorDB for testing` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-west4-gcp\")\n",
    "index_name = \"zac-george-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayoung/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/langchain/llms/openai.py:624: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ayoung/zac-george-gpt/zac-george-gpt/lib/python3.11/site-packages/langchain/chains/qa_with_sources/vector_db.py:60: UserWarning: `VectorDBQAWithSourcesChain` is deprecated - please use `from langchain.chains import RetrievalQAWithSourcesChain`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of Sacks or the give to get model for AI start-ups in the provided content.\n",
      "SOURCES:\n",
      "\n",
      "Elapsed time: 2.877254009246826 seconds\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "def run_retrievalQA_sources_chain(llm,query,docstore):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chain = RetrievalQAWithSourcesChain.from_chain_type(llm,chain_type=\"stuff\",retriever=docstore.as_retriever(k=3))\n",
    "    a = chain({\"question\": query},return_only_outputs=True)\n",
    "    print(a[\"answer\"])\n",
    "    print(a[\"sources\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")\n",
    "\n",
    "def run_vectorDBQA_sources_chain(llm,query,docstore,k):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chain = VectorDBQAWithSourcesChain.from_chain_type(llm,chain_type=\"stuff\",vectorstore=docstore,k=k)\n",
    "    a = chain({\"question\": query},return_only_outputs=True)\n",
    "    print(a[\"answer\"])\n",
    "    print(a[\"sources\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")\n",
    "\n",
    "llm = OpenAIChat(temperature=0)\n",
    "q = \"What does Sacks say about the give to get model for AI start-ups?\"\n",
    "run_vectorDBQA_sources_chain(llm,q,p,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAIChat(model_name=\"gpt-4\",temperature=0)\n",
    "q = \"What is the cause of the SVB crisis?\"\n",
    "run_vectorDBQA_sources_chain(llm,q,p,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`8. Evaluation` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('eval/final_eval.json', 'r') as f:\n",
    "    eval_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "\n",
    "llm = OpenAIChat(temperature=0)\n",
    "chain_gpt3_k_1 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=1,input_key = \"question\")\n",
    "chain_gpt3_k_4 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=4,input_key = \"question\")\n",
    "\n",
    "llm = OpenAIChat(model_name=\"gpt-4\",temperature=0)\n",
    "chain_gpt4_k_1 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=1,input_key = \"question\")\n",
    "chain_gpt4_k_4 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=4,input_key = \"question\")\n",
    "chain_gpt4_k_8 = VectorDBQA.from_chain_type(llm,chain_type=\"stuff\",vectorstore=p,k=8,input_key = \"question\")\n",
    " \n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "from langchain.chat_models import ChatOpenAI \n",
    "eval_chain = QAEvalChain.from_llm(llm=ChatOpenAI(temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(chain):\n",
    "\n",
    "    predictions = []\n",
    "    predicted_dataset = []\n",
    "    latency = []\n",
    "\n",
    "    for data in eval_set:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        new_data = {\"question\": data[\"question\"],\"answer\": data[\"answer\"]}\n",
    "        predictions.append(chain(new_data))\n",
    "        predicted_dataset.append(new_data)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        latency.append(elapsed_time)\n",
    "\n",
    "    return predictions,predicted_dataset,latency\n",
    "\n",
    "predictions_list = []\n",
    "scores_list = []\n",
    "latency_list = []\n",
    "\n",
    "# Eval on chains \n",
    "for i,chain in enumerate([chain_gpt3_k_1,chain_gpt4_k_1,chain_gpt3_k_4,chain_gpt4_k_4,chain_gpt4_k_8]):    \n",
    "    print(f\"Evaluating chain {i+1}\")\n",
    "    predictions,predicted_dataset,latency=run_eval(chain)\n",
    "    predictions_list.append(predictions)\n",
    "    graded_outputs = eval_chain.evaluate(predicted_dataset, predictions, question_key=\"question\", prediction_key=\"result\")\n",
    "    scores_list.append(graded_outputs)\n",
    "    latency_list.append(latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "stor=pd.DataFrame()\n",
    "\n",
    "for i,chunk_size in enumerate([\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]):\n",
    "    d=scores_list[i]\n",
    "    incorrect_counts = []\n",
    "    for dictionary in d:\n",
    "        if dictionary['text'] == 'INCORRECT':\n",
    "            incorrect_counts.append(1)\n",
    "        else:\n",
    "            incorrect_counts.append(0)\n",
    "    stor.loc[chunk_size,'num_incorrect']=sum(incorrect_counts)\n",
    "\n",
    "stor['pct_incorrect'] = stor['num_incorrect']  / len(eval_set)\n",
    "stor['pct_correct'] = 1 - stor['pct_incorrect']\n",
    "stor['pct_correct'].plot(kind='bar')\n",
    "plt.title('Percentage of Correct Answers')\n",
    "plt.xlabel('Chain')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency=pd.DataFrame(latency_list).T\n",
    "latency.columns = [\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]\n",
    "latency.to_csv(\"results/latency.csv\")\n",
    "latency.boxplot()\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Latency per query (seconds)\")\n",
    "plt.title(\"Latency for QA comparing ChatGPT vs GPT4 \\n $\\mu$ per model = 4.7s,13.3s,19.1s, $N=52$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_summary(i):\n",
    "    d=pd.DataFrame(predictions_list[i])\n",
    "    d['score']=list(score[\"text\"] for score in scores_list[i])\n",
    "    return d\n",
    "\n",
    "GPT35_k_4_result=eval_summary(0)\n",
    "GPT4_k_4_result=eval_summary(1)\n",
    "GPT4_k_8_result=eval_summary(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT35_k_4_result.to_csv(\"results/GPT35_k_4_result.csv\")\n",
    "GPT4_k_4_result.to_csv(\"results/GPT4_k_4_result.csv\")\n",
    "GPT4_k_8_result.to_csv(\"results/GPT4_k_8_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong3_5=GPT35_k_4_result[GPT35_k_4_result.score != \"CORRECT\"]\n",
    "wrong3_5.to_csv(\"results/wrong3_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4=GPT4_k_4_result[GPT4_k_4_result.score != \"CORRECT\"]\n",
    "wrong4.to_csv(\"results/wrong4_k4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4=GPT4_k_4_result[GPT4_k_4_result.score != \"CORRECT\"]\n",
    "wrong4.to_csv(\"results/wrong4_k8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT35_k_4_result=pd.read_csv(\"results/GPT35_k_4_result.csv\")\n",
    "GPT4_k_4_result=pd.read_csv(\"results/GPT4_k_4_result.csv\")\n",
    "GPT4_k_8_result=pd.read_csv(\"results/GPT4_k_8_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include corrections to eval (see below):\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1zc3lmm23lRkbU0k0j3ueo69_s5RBb-1qbXGwnx0PW00/edit#gid=1347589790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame([48/51.,50/51.,51/51.]).T\n",
    "d.columns=[\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]\n",
    "d_=d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency = pd.read_csv(\"results/latency.csv\",index_col=None)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "axs[0].set_title(\"Percentage of Correct Answers \\n % per model: 94%, 98%, 100%, $N=52$\")\n",
    "axs[1].set_title(\"Latency for QA comparing ChatGPT vs GPT4 \\n $\\mu$ per model: 4.7s,13.3s,19.1s, $N=52$\")\n",
    "axs[0].set_xlabel('Chain')\n",
    "axs[0].set_ylabel('Fraction correct')\n",
    "axs[1].set_xlabel(\"Model\")\n",
    "axs[1].set_ylabel(\"Latency per query (seconds)\")\n",
    "d_.plot(kind='bar', ax=axs[0], legend=False)\n",
    "latency[[\"GPT3.5_k_4\",\"GPT4_k_4\",\"GPT4_k_8\"]].boxplot(ax=axs[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
