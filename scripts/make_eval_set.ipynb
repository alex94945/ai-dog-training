{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import QAGenerationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ep_text(ep_number):\n",
    "    \"\"\" Fetch episode \"\"\"\n",
    "\n",
    "    episode_id=\"0\"+str(ep_number) \n",
    "    file_path='audio_transcription/%s.txt'%str(episode_id)\n",
    "    transcript=pd.read_csv(file_path,sep='\\t',header=None)\n",
    "    transcript.columns=['links','time','chunks']\n",
    "    transcript['clean_chunks']=transcript['chunks'].astype(str).apply(lambda x: x.strip())\n",
    "    texts = transcript['clean_chunks'].str.cat(sep=' ')\n",
    "    return texts \n",
    "\n",
    "def gen_questions(txt,N,chunk):\n",
    "    \" Generate N questions from context of chunk chars \"\n",
    " \n",
    "    n = len(txt)\n",
    "    starting_indices = [random.randint(0,n-chunk) for _ in range(N)]\n",
    "    sub_sequences = [txt[i:i+chunk] for i in starting_indices]\n",
    "    chain = QAGenerationChain.from_llm(ChatOpenAI(temperature = 0))\n",
    "    eval_set = []\n",
    "    for i, b in enumerate(sub_sequences):\n",
    "        print(\"%s\"%str(i+1))\n",
    "        try:\n",
    "            qa = chain.run(b)\n",
    "            eval_set.append(qa)\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "    return eval_set\n",
    "\n",
    "# Pick random episodes\n",
    "all_eval = []\n",
    "random_eps = [random.randint(1, 121) for _ in range(20)]\n",
    "for ep_number in random_eps:\n",
    "    print(\"EPISODE: %s\"%ep_number)\n",
    "    txt = get_ep_text(ep_number)\n",
    "    # Generate 5 questions from context of 5000 chars\n",
    "    qus = gen_questions(txt,5,5000)\n",
    "    all_eval.append(qus)\n",
    "\n",
    "eval_set_full = list(itertools.chain.from_iterable(all_eval))\n",
    "print(len(eval_set_full))\n",
    "\n",
    "# Save\n",
    "with open('eval/eval_set.json', 'w') as fout:\n",
    "    json.dump(eval_set_full, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
